{
    "cells": [
        {
            "attachments": {},
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "# Outline\n",
                "\n",
                "This notebook complements the blog post and is intended to cover the following:\n",
                "- [Reproducing diarization pipelines](#reproducing-diarization-pipelines)\n",
                "- [Comparing results](#comparing-results)\n",
                "- [Deep dive and error analysis](#deep-dive-and-error-analysis)\n",
                "- [Conclusion](#conclusion)\n",
                "- [Score and analyze your own data](#score-and-analyze-your-own-data)\n",
                "- [Appendix](#appendix)\n"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "# Reproducing diarization pipelines<a id='reproducing-diarization-pipelines'></a>"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## Setup\n"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "If you have cloned the repro and are running this locally, make sure you first follow setup in `tdrz_dev/README.md`. This notebook handles the rest of the setup (including downloading eval data).\n",
                "\n",
                "> *NOTE: If running on Google Colab - until we figure out how to get the fstalign scoring tool working there - this notebook will fetch pre-computed scored results. You can still run the error inspection and analysis sections.*"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 1,
            "metadata": {},
            "outputs": [],
            "source": [
                "import matplotlib.pyplot as plt\n",
                "from IPython import get_ipython\n",
                "from IPython import display as ipd"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 2,
            "metadata": {
                "tags": []
            },
            "outputs": [],
            "source": [
                "if 'google.colab' in str(get_ipython()):\n",
                "    # clone a particular branch of tinydiarize repo\n",
                "    ! git clone https://github.com/akashmjn/tinydiarize.git\n",
                "    # pip install\n",
                "    ! pip install -e tinydiarize\n",
                "    # setup workdir\n",
                "    WORKDIR = 'tinydiarize/tdrz_dev/workdir_analysis'\n",
                "    CODEDIR = 'tinydiarize/tdrz_dev'\n",
                "    _PRE_COMPUTED = True\n",
                "else:\n",
                "    # if running locally, assume that tinydiarize repo is already cloned and setup\n",
                "    WORKDIR = '../workdir_analysis'\n",
                "    CODEDIR = '..'\n",
                "    _PRE_COMPUTED = False\n",
                "\n",
                "# _PRE_COMPUTED = True  # comment out if you want to just quickly step through analysis\n",
                "\n",
                "ipd.clear_output()"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 4,
            "metadata": {},
            "outputs": [],
            "source": [
                "# setup workdir structure and fetch evaluation data\n",
                "if _PRE_COMPUTED:\n",
                "    # download pre-computed results from blob\n",
                "    ! wget -O {CODEDIR}/workdir_analysis.tar.gz https://sharedstorage7190.blob.core.windows.net/tinydiarize/precomputed/workdir_analysis-060823/24ce3e95e3d8d0b8efd4395d5f9e5f0dc07d5078cc5ec00aca6b4b61129fa5d5.tar.gz\n",
                "    # compute the SHA256 hash of the downloaded file\n",
                "    ! echo \"SHA256 hash of downloaded file: $(sha256sum {CODEDIR}/workdir_analysis.tar.gz)\"\n",
                "    # unpack pre-computed results into WORKDIR\n",
                "    ! tar -xzf {CODEDIR}/workdir_analysis.tar.gz -C {CODEDIR}\n",
                "else:\n",
                "    ! mkdir -p {WORKDIR}\n",
                "    # call a bash script with WORKDIR as an environment variable and fetch eval data\n",
                "    ! bash {CODEDIR}/scripts/fetch_earnings21_calls.sh {WORKDIR}\n",
                "\n",
                "ipd.clear_output()"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# listen to an example file \n",
                "ipd.Audio(f'{WORKDIR}/audio/earnings21-4374910.mp3')"
            ]
        },
        {
            "attachments": {},
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## Transcribing and scoring\n",
                "\n",
                "We use the `run_pipelines.py` convenience script to transcribe and score the calls. It runs ASR (Whisper `small.en`) along with various diarization pipelines (explained in the following sections), scores them and parses detailed results into a single tsv file. Make sure you have completed the setup steps above and have an appropriate token file.\n",
                "\n",
                "> *NOTE: On Google colab, we skip this step and use pre-computed results from my runs, as it's currently tricky to setup the fstalign scoring tool*"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "if not _PRE_COMPUTED:\n",
                "    # change directory to ../scripts\n",
                "    %cd {CODEDIR}/scripts\n",
                "\n",
                "    # process all the selected calls\n",
                "    calls = [\n",
                "        (\"earnings21-4385939\", 19),\n",
                "        (\"earnings21-4374910\", 2),\n",
                "        (\"earnings21-4359971\", 10),\n",
                "    ]\n",
                "\n",
                "    # iterate over calls and run the script run_pipelines.py\n",
                "    for call_id, num_speakers in calls:\n",
                "        # provide the oracle # speakers to pipelines that do clustering as we only evaluate local diarization i.e. segmentation\n",
                "        ! python run_pipelines.py {WORKDIR}/audio/{call_id}.mp3 {WORKDIR}/fstalign_scoring/references/{call_id}-ref.nlp {WORKDIR}/transcripts --num_speakers {num_speakers} --hf_token_file \"HF_TOK.txt\"\n",
                "\n",
                "    # change directory back to ../notebooks\n",
                "    %cd {CODEDIR}/notebooks\n"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "# Comparing results<a id='comparing-results'></a>"
            ]
        },
        {
            "attachments": {},
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## Evaluation data\n",
                "\n",
                "We adopt the zero-shot evaluation scheme of Whisper, testing on a different dataset than the tinydiarize model was finetuned on (`AMI meetings`). This helps us get a more realistic estimate of real-world generalization vs the model's ability to fit `AMI meetings` dataset-specific quirks.\n",
                "\n",
                "For ease of analysis (and keeping with the 'tiny' spirit ðŸ˜‰) I've chosen a biased subset of 3 earnings calls from [rev/earnings21](https://github.com/revdotcom/speech-datasets/blob/main/earnings21/earnings21-file-metadata.csv). These were selected with the following criteria:\n",
                "- One interactive Q&A meeting (*939, Hershey) with a higher number of speaker switches and unique speakers\n",
                "- One meeting (*910, Amex) that is a moderated Q&A between only 2 speakers\n",
                "- One meeting (*971, Constellium) that comprises both a presentation and Q&A session, and is somewhere in between\n",
                "\n",
                "| file_id | audio_length | company_name | sector | speaker_switches | speaker_switches / minute | unique_speakers |\n",
                "|---------|--------------|--------------|--------|------------------|---------------------------|-----------------|\n",
                "| 4385939 | 3049.832     | Hershey Company | Consumer Goods | 132 | 2.60 | 19 |\n",
                "| 4374910 | 2028.536     | American Express Company | Financial | 56 | 1.66 | 2 |\n",
                "| 4359971 | 3759.944     | Constellium | Industrial Goods | 116 | 1.85 | 10 |"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## Information on metrics\n",
                "\n",
                "Diarization typically uses either time-based metrics (e.g. DER measures % of time correctly attributed) or transcript-based metrics that compare the final transcript. \n",
                "\n",
                "I prefer to use transcript-based metrics as:\n",
                "- It helps us see errors the way an end-user would i.e. [WYSIWYG](https://en.wikipedia.org/wiki/WYSIWYG).\n",
                "- Analyzing errors in the semantic context of the conversation is much more intuitive, and helps us quickly get a sense of where we really need to focus.\n",
                "- Tricky edge cases such as disfluencies, speaker overlap, etc. can be handled in an interpretable way via the transcription convention (e.g. using special tokens and/or text normalization).\n",
                "\n",
                "In this notebook we focus on \"local\" diarization i.e. speaker segmentation (and not the \"global\" task of clustering speakers across the entire meeting). We use the following metrics for ease of interpretation and analysis:\n",
                "- WER: word error rate as measured by `fstalign`\n",
                "- Speaker turn recall: fraction of speaker changes that are correctly identified\n",
                "- Speaker turn precision: fraction of predicted speaker changes that are correct\n",
                "\n",
                "Just like WER, speaker turn recall and precision are computed by aligning reference and hypothesis transcripts after inserting a special `speaker__turn` token, and then counting errors on the special tokens. We also parse the aligned ref/hyp transcripts for error analysis. *(see implementation in `score.py` for details)*"
            ]
        },
        {
            "attachments": {},
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## Compiling results"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 3,
            "metadata": {},
            "outputs": [],
            "source": [
                "# some utility functions\n",
                "%load_ext autoreload\n",
                "%autoreload 2\n",
                "import sys; sys.path.extend([CODEDIR, f\"{CODEDIR}/notebooks\"])\n",
                "from analysis_utils import compile_results, summarize_results, query_metric_results, plot_metric_results, inspect_spk_errors"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "We compile all the TSV files generated by `run_pipelines.py` into a single dataframe for analysis. The dataframe contains both WER and speaker turn metrics along with a detailed error breakdown e.g. (DEL/INS/SUB) for WER, false negatives (DEL/SUB) for speaker turn recall, and false positives (INS/SUB) for speaker turn precision. \n",
                "\n",
                "We also parse a useful `*.sbs` file output by fstalign containing ref/hyp aligned with the errors. This is very helpful for error inspection and debugging."
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 4,
            "metadata": {},
            "outputs": [
                {
                    "name": "stdout",
                    "output_type": "stream",
                    "text": [
                        "Read 84 results from 21 files\n",
                        "Read 21 side-by-side analysis results\n"
                    ]
                }
            ],
            "source": [
                "results_all_df, analysis_results = compile_results(f\"{WORKDIR}/fstalign_scoring/results\")"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "We compare the following approaches:\n",
                "- `punctuation`: Simple baseline adding a speaker turn after every ending punctuation e.g. `.?!`. The recall of this baseline helps us get a sense for how well Whisper is already implicitly marking speaker turns (i.e. does it miss any). We hypothesize that the semantic context of a conversation is a strong signal for both punctuations and speaker turns.\n",
                "\n",
                "- `pyannote_pre_sr`: Runs full pyannote diarization pipeline, and then whisper.transcribe on segments created by the pipeline, retaining the speaker assignment for each segment. [Pyannote](https://huggingface.co/pyannote/speaker-diarization) is a strong open-source baseline that runs dedicated 2-stage diarization models (segmentation + clustering).\n",
                "\n",
                "- `segment_timestamped`: Simple baseline that separates every time segment created by Whisper (e.g. 00:27.080 --> 00:32.720 \"this is a segment\") with a speaker turn. Similar to `punctuation`, the recall of this simple baseline helps us get a rough upper bound for how well [clustering Whisper segments](https://huggingface.co/spaces/vumichien/Whisper_speaker_diarization) can do.\n",
                "\n",
                "- `tdrz_token`: tinydiarize model introducing a new `speaker_turn` token in the vocabulary which is decoded in whisper.transcribe itself. It was finetuned on ~100hrs from the AMI meetings dataset prepared into long-form 30s chunks. Viewing this as a special case of punctuations, we'd expect this to have a much better precision than the `punctuation` baseline, with its recall as an upper bound. \n",
                "\n",
                "Our aim here is not to claim a new state of the art or anything but to (i) study whether Whisper already has a useful internal representation (ii) see how well we can extract that representation via a tiny finetuning budget (iii) see if we can retain original WER performance without overfitting to the finetuning dataset.\n",
                "\n",
                "If it works, this approach has the advantage of much simpler and faster inference that can be easily integrated into optimized pipelines like [whisper.cpp](https://github.com/ggerganov/whisper.cpp)."
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 5,
            "metadata": {},
            "outputs": [
                {
                    "name": "stdout",
                    "output_type": "stream",
                    "text": [
                        "Total # of words: 23630, Total # of speaker turns: 301\n"
                    ]
                },
                {
                    "data": {
                        "text/html": [
                            "<div>\n",
                            "<style scoped>\n",
                            "    .dataframe tbody tr th:only-of-type {\n",
                            "        vertical-align: middle;\n",
                            "    }\n",
                            "\n",
                            "    .dataframe tbody tr th {\n",
                            "        vertical-align: top;\n",
                            "    }\n",
                            "\n",
                            "    .dataframe thead tr th {\n",
                            "        text-align: left;\n",
                            "    }\n",
                            "\n",
                            "    .dataframe thead tr:last-of-type th {\n",
                            "        text-align: right;\n",
                            "    }\n",
                            "</style>\n",
                            "<table border=\"1\" class=\"dataframe\">\n",
                            "  <thead>\n",
                            "    <tr>\n",
                            "      <th>model</th>\n",
                            "      <th colspan=\"3\" halign=\"left\">small.en</th>\n",
                            "      <th>small.en-tdrz</th>\n",
                            "    </tr>\n",
                            "    <tr>\n",
                            "      <th>method</th>\n",
                            "      <th>punctuation</th>\n",
                            "      <th>pyannote_pre_sr</th>\n",
                            "      <th>segment_timestamped</th>\n",
                            "      <th>tdrz_token</th>\n",
                            "    </tr>\n",
                            "    <tr>\n",
                            "      <th>metric</th>\n",
                            "      <th></th>\n",
                            "      <th></th>\n",
                            "      <th></th>\n",
                            "      <th></th>\n",
                            "    </tr>\n",
                            "  </thead>\n",
                            "  <tbody>\n",
                            "    <tr>\n",
                            "      <th>spk_turn_precision</th>\n",
                            "      <td>19.5</td>\n",
                            "      <td>83.4</td>\n",
                            "      <td>14.5</td>\n",
                            "      <td>97.7</td>\n",
                            "    </tr>\n",
                            "    <tr>\n",
                            "      <th>spk_turn_recall</th>\n",
                            "      <td>92.0</td>\n",
                            "      <td>78.4</td>\n",
                            "      <td>86.7</td>\n",
                            "      <td>70.8</td>\n",
                            "    </tr>\n",
                            "    <tr>\n",
                            "      <th>wer_overall</th>\n",
                            "      <td>10.9</td>\n",
                            "      <td>12.9</td>\n",
                            "      <td>10.9</td>\n",
                            "      <td>10.3</td>\n",
                            "    </tr>\n",
                            "    <tr>\n",
                            "      <th>wer_speaker_switch</th>\n",
                            "      <td>15.0</td>\n",
                            "      <td>23.1</td>\n",
                            "      <td>15.0</td>\n",
                            "      <td>15.5</td>\n",
                            "    </tr>\n",
                            "  </tbody>\n",
                            "</table>\n",
                            "</div>"
                        ],
                        "text/plain": [
                            "model                 small.en                                       \n",
                            "method             punctuation pyannote_pre_sr segment_timestamped   \n",
                            "metric                                                               \n",
                            "spk_turn_precision        19.5            83.4                14.5  \\\n",
                            "spk_turn_recall           92.0            78.4                86.7   \n",
                            "wer_overall               10.9            12.9                10.9   \n",
                            "wer_speaker_switch        15.0            23.1                15.0   \n",
                            "\n",
                            "model              small.en-tdrz  \n",
                            "method                tdrz_token  \n",
                            "metric                            \n",
                            "spk_turn_precision          97.7  \n",
                            "spk_turn_recall             70.8  \n",
                            "wer_overall                 10.3  \n",
                            "wer_speaker_switch          15.5  "
                        ]
                    },
                    "metadata": {},
                    "output_type": "display_data"
                },
                {
                    "data": {
                        "image/png": "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",
                        "text/plain": [
                            "<Figure size 900x350 with 2 Axes>"
                        ]
                    },
                    "metadata": {},
                    "output_type": "display_data"
                }
            ],
            "source": [
                "summary_df, results_df = summarize_results(results_all_df)\n",
                "ipd.display(summary_df)\n",
                "\n",
                "# plotting per-meeting speaker turn results\n",
                "fig, axes = plt.subplots(1, 2, figsize=(9, 3.5), sharey=True)\n",
                "d1 = query_metric_results(results_df, \"spk_turn_recall\", groups=[\"call_id\", \"method\"])\n",
                "plot_metric_results(d1, title=\"Speaker Turn Recall\", ax=axes[0], legend=False)\n",
                "d2 = query_metric_results(results_df, \"spk_turn_precision\", groups=[\"call_id\", \"method\"])\n",
                "plot_metric_results(d2, title=\"Speaker Turn Precision\", ax=axes[1])"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "Going through the results, we can make the following observations:\n",
                "1. The recall of the simple `punctuation` baseline is quite high i.e. it rarely misses punctuating a speaker turn. This validates our hypothesis that the model already has a good implicit representation of speaker turns via both acoustic and semantic cues (much like a punctuation).\n",
                "2. The `pyannote_pre_sr` pipeline has the best all-round performance, but not as good recall or precision as the best individual methods. As we'll see in the next section, this is due to a design limitation that hinders its performance on short segments and quick speaker changes.\n",
                "3. The recall of the `segment_timestamped` baseline is somewhat erratic compared to `punctuation`, with a big gap on call `*910`. I have also found it to be quite sensitive to other decoding parameters (e.g. previous_text_context). This aligns with common observations on the instability of Whisper timestamps.\n",
                "4. The `tdrz_token` approach significantly improves precision over the punctuation baseline to almost 100%, while incurring some loss of recall. Strong performance with a very simple finetuning setup confirms that we can cheaply isolate representations that were already present in Whisper models.\n",
                "\n",
                "In the next section, by manually inspecting errors we can build some intuition for the strengths and weaknesses of different approaches."
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "# Deep dive and error analysis<a id='deep-dive-and-error-analysis'></a>"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## Error inspection\n",
                "\n",
                "We now look through some examples to understand where the bottlenecks lie. Our choice of transcript-based metrics (speaker turn precision/recall) allows us to do this in a very interpretable way, by simply reading the aligned transcripts around speaker turn errors.\n",
                "\n",
                "We will see that:\n",
                "- Short segments (e.g. \"yeah okay\") and quick speaker changes are hard for `pyannote_pre_sr` because it uses acoustic embeddings to tell speakers apart locally. It is hard for even us to recognize a speaker from just a 1s audio clip - so the smaller the time unit, the worse the acoustic embeddings. This is a limitation of such approaches.\n",
                "- Whisper can use the semantic context to make this problem much easier. Being trained to output punctuations helps it have a high recall on speaker turns, even in short segments.\n",
                "- Finetuning `tdrz_token` to directly output speaker turns doesn't have as high recall as punctuations yet, although seems promising given the relatively cheap setup.\n",
                "- Precision errors incurred by `pyannote_pre_sr` are also related to the short segment issue, where `tdrz_token` has a clear advantage."
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 6,
            "metadata": {},
            "outputs": [],
            "source": [
                "# listen to an example file\n",
                "call_id = \"4385939\"\n",
                "ipd.Audio(f'{WORKDIR}/audio/earnings21-{call_id}.mp3')"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "### Recall errors: Short segments and importance of semantic context\n",
                "\n",
                "We step through individual `recall_errors` below and have categorized them into the following types:\n",
                "\n",
                "|Error type|pyannote_pre_sr|punctuation|tdrz_token|\n",
                "|:----|:----|:----|:----|\n",
                "|Recall|85%|95%|74%|\n",
                "|# false negatives (out of 131)|19|6|34|\n",
                "|invalid|2|2|4|\n",
                "|ASR deletion|6|4|12|\n",
                "|short segment|11|0|10|\n",
                "|other segment|0|0|8|"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "#### pyannote_pre_sr (recall 85%):\n",
                "\n",
                "Most of the errors (11) are around few-word short segments that are merged into surrounding ones. As discussed above, this is because of a design limitation of methods that only rely on acoustic information. *(the smaller the time unit, the worse the acoustic embeddings)*\n",
                "\n",
                "> When we combine pyannote_pre_sr with whisper, it slightly increases recall errors (6 vs 4) because whisper deletes more words when it transcribes the segments cut by pyannote. See the Appendix for more details.\n",
                "\n",
                "On reading through these errors ourselves, we can actually easily identify many of the speaker turns just from the semantic context even without listening to the audio.\n"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 34,
            "metadata": {},
            "outputs": [
                {
                    "name": "stdout",
                    "output_type": "stream",
                    "text": [
                        "Results for: ('small.en', '4385939', 'pyannote_pre_sr')\n",
                        "Precision: 86.15, # of false positives: 18\n",
                        "Recall: 85.50, # of false negatives: 19\n",
                        "\n",
                        " ---------- Spk turn recall errors: ----------\n",
                        "\n",
                        "Line: 3263, Index: 6\n",
                        "                okay\tokay                \t\t\t\n",
                        "              thanks\tthanks              \t\t\t\n",
                        "                  so\tso                  \t\t\t\n",
                        "                much\tmuch                \t\t\t\n",
                        "                 for\tfor                 \t\t\t\n",
                        "                 the\tthe                 \t\t\t\n",
                        "               color\tcolor               \t\t\t\n",
                        "               there\tthere               \t\t\t\n",
                        "       speaker__turn\tspeaker__turn       \t\t\t\n",
                        "          absolutely\tabsolutely          \t\t\t\n",
                        "       speaker__turn\t<del>               \tERR\t___41_SPEAKER_TURN___\t41|\n",
                        "               thank\tthank               \t\t\t\n",
                        "                 you\tyou                 \t\t\t\n",
                        "                 our\tour                 \t\t\t\n",
                        "                next\tnext                \t\t\t\n",
                        "            question\tquestion            \t\t\t\n",
                        "               comes\tcomes               \t\t\t\n",
                        "                from\tfrom                \t\t\t\n",
                        "               <ins>\tthe                 \t\t\t\n",
                        "                line\tline                \t\t\t\n",
                        "                  of\tof                  \t\t\t\n"
                    ]
                }
            ],
            "source": [
                "# manually tagged errors:\n",
                "# 0,7,8,10,11,13  - ASR deletion\n",
                "# 1,2,3,6*,9,12,14,15,16,17,18  - short segment\n",
                "# 4,5 - invalid (nonverbal speech)\n",
                "\n",
                "# edit the list passed to recall_errors to inspect different error by tagged index\n",
                "inspect_spk_errors(results_df, analysis_results, (\"small.en\", call_id, \"pyannote_pre_sr\"), recall_errors=[6])"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "#### punctuation (recall 95%):\n",
                "\n",
                "Due to availability of semantic context to Whisper's decoder, we see none of the short segment recall errors above. Whisper almost always places punctuations to demarcate different speakers. The only remaining errors are ASR deletions (similar to those seen above)."
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 35,
            "metadata": {},
            "outputs": [
                {
                    "name": "stdout",
                    "output_type": "stream",
                    "text": [
                        "Results for: ('small.en', '4385939', 'punctuation')\n",
                        "Precision: 20.90, # of false positives: 473\n",
                        "Recall: 95.42, # of false negatives: 6\n",
                        "\n",
                        " ---------- Spk turn recall errors: ----------\n",
                        "\n",
                        "Line: 6714, Index: 3\n",
                        "                  we\twe                  \t\t\t\n",
                        "                sell\tsell                \t\t\t\n",
                        "                  in\tin                  \t\t\t\n",
                        "              bricks\tbricks              \t\t\t\n",
                        "                 and\tand                 \t\t\t\n",
                        "              mortar\tmortar              \t\t\t\n",
                        "              steve-\t<del>               \t\t\t\n",
                        "       speaker__turn\tspeaker__turn       \t\t\t\n",
                        "               right\t<del>               \t\t\t\n",
                        "               right\t<del>               \t\t\t\n",
                        "       speaker__turn\tsteve               \tERR\t___84_SPEAKER_TURN___\t84|\n",
                        "            anything\tanything            \t\t\t\n",
                        "                 you\tyou                 \t\t\t\n",
                        "               <ins>\twant                \t\t\t\n",
                        "               wanna\tto                  \t\t\t\n",
                        "                 add\tadd                 \t\t\t\n",
                        "       speaker__turn\tspeaker__turn       \t\t\t\n",
                        "                yeah\tyeah                \t\t\t\n",
                        "                   i\ti                   \t\t\t\n",
                        "               would\twould               \t\t\t\n",
                        "                 say\tsay                 \t\t\t\n"
                    ]
                }
            ],
            "source": [
                "# manually tagged recall errors:\n",
                "# 0,5 - invalid (nonverbal speech)\n",
                "# 1,2,3*,4 - ASR deletion\n",
                "inspect_spk_errors(results_df, analysis_results, (\"small.en\", call_id, \"punctuation\"), recall_errors=[3])"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "#### tdrz_token (recall 74%):\n",
                "\n",
                "In an ideal case - we'd like to combine the high recall of the `punctuation` baseline, with a better precision as we assign a special token.\n",
                "\n",
                "However we can see that there's still some room to improve on recall. No particular error type stands out, so it's possible that the current model favors precision over recall and will improve with a better finetuning setup."
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 7,
            "metadata": {},
            "outputs": [
                {
                    "name": "stdout",
                    "output_type": "stream",
                    "text": [
                        "Results for: ('small.en-tdrz', '4385939', 'tdrz_token')\n",
                        "Precision: 98.98, # of false positives: 1\n",
                        "Recall: 74.05, # of false negatives: 34\n",
                        "\n",
                        " ---------- Spk turn recall errors: ----------\n",
                        "\n",
                        "Line: 9385, Index: 32\n",
                        "                 the\tthe                 \t\t\t\n",
                        "               floor\tfloor               \t\t\t\n",
                        "                back\tback                \t\t\t\n",
                        "                  to\tto                  \t\t\t\n",
                        "                  ms\tms                  \t\t\t\n",
                        "               poole\tpoole               \t\t\t\n",
                        "                 for\tfor                 \t\t\t\n",
                        "                 any\tany                 \t\t\t\n",
                        "               final\tfinal               \t\t\t\n",
                        "            comments\tcomments            \t\t\t\n",
                        "       speaker__turn\t<del>               \tERR\t___129_SPEAKER_TURN___\t129|\n",
                        "               thank\tthank               \t\t\t\n",
                        "                 you\tyou                 \t\t\t\n",
                        "                 all\tall                 \t\t\t\n",
                        "                 for\tfor                 \t\t\t\n",
                        "             joining\tjoining             \t\t\t\n",
                        "                  us\tus                  \t\t\t\n",
                        "                this\tthis                \t\t\t\n",
                        "             morning\tmorning             \t\t\t\n",
                        "                   i\ti                   \t\t\t\n",
                        "                will\twill                \t\t\t\n"
                    ]
                }
            ],
            "source": [
                "# manually tagged recall errors:\n",
                "# 0,1,23*,24,28,29,32*,33 - other segment \n",
                "# 5,15,16,17,18,19,22,27,30,31 - short segment\n",
                "# 2,3,4,8,9,10,11,12,13,14,20,21 - ASR deletion\n",
                "# 6,7,25,26 - invalid (nonverbal speech)\n",
                "inspect_spk_errors(results_df, analysis_results, (\"small.en-tdrz\", call_id, \"tdrz_token\"), recall_errors=[32])"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "### Precision errors\n",
                "\n",
                "Most precision errors for `pyannote_pre_sr` are because it can often split the audio into small overlapped segments that are not needed. These segments can either contain duplicate speech that is already in other segments or be false alarms. This happens more often when speakers change quickly, and is related to the time resolution design limitation discussed above.\n",
                "\n",
                "Sometimes these overlapping segments are also written in the wrong order (serialization error), which is another problem. ([discussed later](#combining-pyannote-and-transcription-pipelines))\n",
                "\n",
                "Meanwhile, the `tdrz_token` model has near 100% precision, showing that the extra `speaker_turn` token has quickly learned to be a strong indicator of speaker turns. This is a very promising result, as it shows that we can cheaply isolate behavior that was already present in Whisper models.\n",
                "\n",
                "|Error type|pyannote_pre_sr|tdrz_token|\n",
                "|:----|:----|:----|\n",
                "|Precision|86%|99%|\n",
                "|# predictions|130|96|\n",
                "|# false positives|18|1|\n",
                "|duplicate segment|3|0|\n",
                "|extra segment|6|1|\n",
                "|duplicate + serialization error|3|0|\n",
                "|extra + serialization error|6|0|"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 37,
            "metadata": {
                "tags": []
            },
            "outputs": [
                {
                    "name": "stdout",
                    "output_type": "stream",
                    "text": [
                        "Results for: ('small.en', '4385939', 'pyannote_pre_sr')\n",
                        "Precision: 86.15, # of false positives: 18\n",
                        "Recall: 85.50, # of false negatives: 19\n",
                        "\n",
                        " ---------- Spk turn precision errors: ----------\n",
                        "\n",
                        "Line: 4772, Index: 11\n",
                        "                  an\tan                  \t\t\t\n",
                        "                even\teven                \t\t\t\n",
                        "             greater\tgreater             \t\t\t\n",
                        "              amount\tamount              \t\t\t\n",
                        "                  of\tof                  \t\t\t\n",
                        "             pricing\tpricing             \t\t\t\n",
                        "               power\tpower               \t\t\t\n",
                        "       speaker__turn\tspeaker__turn       \t\t\t\n",
                        "              really\treally              \t\t\t\n",
                        "             helpful\thelpful             \t\t\t\n",
                        "               <ins>\tspeaker__turn       \tERR\t\t\n",
                        "               <ins>\treally              \t\t\t\n",
                        "               <ins>\thelpful             \t\t\t\n",
                        "               thank\tthank               \t\t\t\n",
                        "                 you\tyou                 \t\t\t\n",
                        "                  so\tso                  \t\t\t\n",
                        "                much\tmuch                \t\t\t\n",
                        "       speaker__turn\tspeaker__turn       \t\t\t\n",
                        "               thank\tthank               \t\t\t\n",
                        "                 you\tyou                 \t\t\t\n",
                        "                 our\tour                 \t\t\t\n"
                    ]
                }
            ],
            "source": [
                "# manually tagged precision errors:\n",
                "# 0,8,11* - duplicate segment\n",
                "# 1,2,4,5,6,17 - extra segment\n",
                "# 3,7,12 - duplicate + serialisation\n",
                "# 9,10,13,14,15,16 - extra segment + serialisation \n",
                "\n",
                "# in the example below there is a duplicate segment containing \"really helpful\"\n",
                "inspect_spk_errors(results_df, analysis_results, (\"small.en\", call_id, \"pyannote_pre_sr\"), precision_errors=[11])"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 8,
            "metadata": {},
            "outputs": [
                {
                    "name": "stdout",
                    "output_type": "stream",
                    "text": [
                        "Results for: ('small.en-tdrz', '4385939', 'tdrz_token')\n",
                        "Precision: 98.98, # of false positives: 1\n",
                        "Recall: 74.05, # of false negatives: 34\n"
                    ]
                }
            ],
            "source": [
                "# 0 - short extra segment\n",
                "inspect_spk_errors(results_df, analysis_results, (\"small.en-tdrz\", call_id, \"tdrz_token\"))"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "# Conclusion<a id=\"conclusion\"></a>\n",
                "\n",
                "In conclusion, we have shown that:\n",
                "\n",
                "- Whisper models already have a good internal representation of speaker turns via both acoustic and semantic cues.\n",
                "- Their placement of `punctuation` tokens appears to be very consistent with speaker turns (high recall).\n",
                "- Whisper's time segments `segment_timestamped` (used for clustering [here](https://huggingface.co/spaces/vumichien/Whisper_speaker_diarization)) are less consistent.\n",
                "- Acoustic embedding-based diarization methods like `pyannote_pre_sr` perform well overall, but struggle with short segments & quick speaker turns. This leaves a gap with the best individual precision or recall.\n",
                "- `tdrz_token` shows that we can extract Whisper's speaker representations cheaply, and with small word error rate impact.\n",
                "- With improvements to finetuning, strong performance can be expected as it can use both voice and semantic context to tell speakers apart, which is a unique benefit of this approach."
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 9,
            "metadata": {},
            "outputs": [
                {
                    "data": {
                        "text/html": [
                            "<div>\n",
                            "<style scoped>\n",
                            "    .dataframe tbody tr th:only-of-type {\n",
                            "        vertical-align: middle;\n",
                            "    }\n",
                            "\n",
                            "    .dataframe tbody tr th {\n",
                            "        vertical-align: top;\n",
                            "    }\n",
                            "\n",
                            "    .dataframe thead tr th {\n",
                            "        text-align: left;\n",
                            "    }\n",
                            "\n",
                            "    .dataframe thead tr:last-of-type th {\n",
                            "        text-align: right;\n",
                            "    }\n",
                            "</style>\n",
                            "<table border=\"1\" class=\"dataframe\">\n",
                            "  <thead>\n",
                            "    <tr>\n",
                            "      <th>model</th>\n",
                            "      <th colspan=\"3\" halign=\"left\">small.en</th>\n",
                            "      <th>small.en-tdrz</th>\n",
                            "    </tr>\n",
                            "    <tr>\n",
                            "      <th>method</th>\n",
                            "      <th>punctuation</th>\n",
                            "      <th>pyannote_pre_sr</th>\n",
                            "      <th>segment_timestamped</th>\n",
                            "      <th>tdrz_token</th>\n",
                            "    </tr>\n",
                            "    <tr>\n",
                            "      <th>metric</th>\n",
                            "      <th></th>\n",
                            "      <th></th>\n",
                            "      <th></th>\n",
                            "      <th></th>\n",
                            "    </tr>\n",
                            "  </thead>\n",
                            "  <tbody>\n",
                            "    <tr>\n",
                            "      <th>spk_turn_precision</th>\n",
                            "      <td>19.5</td>\n",
                            "      <td>83.4</td>\n",
                            "      <td>14.5</td>\n",
                            "      <td>97.7</td>\n",
                            "    </tr>\n",
                            "    <tr>\n",
                            "      <th>spk_turn_recall</th>\n",
                            "      <td>92.0</td>\n",
                            "      <td>78.4</td>\n",
                            "      <td>86.7</td>\n",
                            "      <td>70.8</td>\n",
                            "    </tr>\n",
                            "    <tr>\n",
                            "      <th>wer_overall</th>\n",
                            "      <td>10.9</td>\n",
                            "      <td>12.9</td>\n",
                            "      <td>10.9</td>\n",
                            "      <td>10.3</td>\n",
                            "    </tr>\n",
                            "    <tr>\n",
                            "      <th>wer_speaker_switch</th>\n",
                            "      <td>15.0</td>\n",
                            "      <td>23.1</td>\n",
                            "      <td>15.0</td>\n",
                            "      <td>15.5</td>\n",
                            "    </tr>\n",
                            "  </tbody>\n",
                            "</table>\n",
                            "</div>"
                        ],
                        "text/plain": [
                            "model                 small.en                                       \n",
                            "method             punctuation pyannote_pre_sr segment_timestamped   \n",
                            "metric                                                               \n",
                            "spk_turn_precision        19.5            83.4                14.5  \\\n",
                            "spk_turn_recall           92.0            78.4                86.7   \n",
                            "wer_overall               10.9            12.9                10.9   \n",
                            "wer_speaker_switch        15.0            23.1                15.0   \n",
                            "\n",
                            "model              small.en-tdrz  \n",
                            "method                tdrz_token  \n",
                            "metric                            \n",
                            "spk_turn_precision          97.7  \n",
                            "spk_turn_recall             70.8  \n",
                            "wer_overall                 10.3  \n",
                            "wer_speaker_switch          15.5  "
                        ]
                    },
                    "metadata": {},
                    "output_type": "display_data"
                }
            ],
            "source": [
                "ipd.display(summary_df)"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "# Score and analyze your own data<a id=\"score-and-analyze-your-own-data\"></a>\n",
                "\n",
                "To do so, you will need to:\n",
                "- Replace files under `WORKDIR/audio` with your own audio files\n",
                "- Create reference files in the [fstalign NLP format](https://github.com/revdotcom/fstalign/blob/develop/docs/NLP-Format.md]) under `WORKDIR/fstalign_scoring/references` \n",
                "- Make sure that the NLP contains speaker IDs in column 2. These are only used to score speaker turns. If your transcript only has speaker turns without global IDs, you can just increment a dummy speaker ID after every turn.\n",
                "\n",
                "Once this is done, you can simply plug it in to the `run_pipelines.py` script as above."
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "# Appendix<a id=\"appendix\"></a>\n",
                "\n",
                "In this section we go over some miscellaneous notes and observations that didn't fit in the main sections."
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "### Runtime comparison\n",
                "\n",
                "These numbers were tested using the earnings21-4374910 call (33.8 min) on a Quadro RTX 5000 GPU. Whisper is run with beam_size=4 and condition_on_previous_text=True.\n",
                "\n",
                "- The pyannote diarization pipeline takes an extra ~47% of transcription time. This includes 2 steps: local speaker segmentation + global clustering.\n",
                "- To get an idea of the time taken for the global clustering step, I tested a naive clustering of Whisper produced segments (see `drz_post_sr` in `run_pipelines.py`). This is quite fast, taking only 3% of transcription time, implying that the segmentation step is likely the main bottleneck in pyannote.\n",
                "- Lastly, we see that speaker segmentation done by `tdrz_token` is much cheaper, taking 8% extra transcription time. The extra time is a mix of the marginal cost of decoding extra `speaker_turn` tokens, and a couple of more hallucinations from the finetuned model.\n",
                "\n",
                "|Stage|Runtime (s)|Extra cost (%)|\n",
                "|:----|:----|:----|\n",
                "|Whisper.transcribe|121.2|-|\n",
                "|Pyannote diarization|56.6|47%|\n",
                "|Clustering whisper segments|3.4|3%|\n",
                "|Whisper.transcribe (tdrz)|131.5|8%|"
            ]
        },
        {
            "attachments": {},
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "### Impact of fine-tuning\n",
                "\n",
                "While the overall numbers are similar - taking a closer look, we do see some differences in recognition WER (especially deletions)."
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 10,
            "metadata": {},
            "outputs": [
                {
                    "data": {
                        "text/html": [
                            "<div>\n",
                            "<style scoped>\n",
                            "    .dataframe tbody tr th:only-of-type {\n",
                            "        vertical-align: middle;\n",
                            "    }\n",
                            "\n",
                            "    .dataframe tbody tr th {\n",
                            "        vertical-align: top;\n",
                            "    }\n",
                            "\n",
                            "    .dataframe thead th {\n",
                            "        text-align: right;\n",
                            "    }\n",
                            "</style>\n",
                            "<table border=\"1\" class=\"dataframe\">\n",
                            "  <thead>\n",
                            "    <tr style=\"text-align: right;\">\n",
                            "      <th></th>\n",
                            "      <th>call_id</th>\n",
                            "      <th>model</th>\n",
                            "      <th>value</th>\n",
                            "      <th>deletions</th>\n",
                            "      <th>insertions</th>\n",
                            "      <th>substitutions</th>\n",
                            "    </tr>\n",
                            "  </thead>\n",
                            "  <tbody>\n",
                            "    <tr>\n",
                            "      <th>0</th>\n",
                            "      <td>4359971</td>\n",
                            "      <td>small.en</td>\n",
                            "      <td>12.074689</td>\n",
                            "      <td>663</td>\n",
                            "      <td>130</td>\n",
                            "      <td>371</td>\n",
                            "    </tr>\n",
                            "    <tr>\n",
                            "      <th>0</th>\n",
                            "      <td>4359971</td>\n",
                            "      <td>small.en-tdrz</td>\n",
                            "      <td>14.579226</td>\n",
                            "      <td>149</td>\n",
                            "      <td>590</td>\n",
                            "      <td>666</td>\n",
                            "    </tr>\n",
                            "    <tr>\n",
                            "      <th>0</th>\n",
                            "      <td>4374910</td>\n",
                            "      <td>small.en</td>\n",
                            "      <td>9.937005</td>\n",
                            "      <td>322</td>\n",
                            "      <td>41</td>\n",
                            "      <td>126</td>\n",
                            "    </tr>\n",
                            "    <tr>\n",
                            "      <th>0</th>\n",
                            "      <td>4374910</td>\n",
                            "      <td>small.en-tdrz</td>\n",
                            "      <td>6.825107</td>\n",
                            "      <td>53</td>\n",
                            "      <td>99</td>\n",
                            "      <td>184</td>\n",
                            "    </tr>\n",
                            "    <tr>\n",
                            "      <th>0</th>\n",
                            "      <td>4385939</td>\n",
                            "      <td>small.en</td>\n",
                            "      <td>10.298820</td>\n",
                            "      <td>622</td>\n",
                            "      <td>84</td>\n",
                            "      <td>228</td>\n",
                            "    </tr>\n",
                            "    <tr>\n",
                            "      <th>0</th>\n",
                            "      <td>4385939</td>\n",
                            "      <td>small.en-tdrz</td>\n",
                            "      <td>7.543008</td>\n",
                            "      <td>85</td>\n",
                            "      <td>232</td>\n",
                            "      <td>367</td>\n",
                            "    </tr>\n",
                            "  </tbody>\n",
                            "</table>\n",
                            "</div>"
                        ],
                        "text/plain": [
                            "   call_id          model      value  deletions  insertions  substitutions\n",
                            "0  4359971       small.en  12.074689        663         130            371\n",
                            "0  4359971  small.en-tdrz  14.579226        149         590            666\n",
                            "0  4374910       small.en   9.937005        322          41            126\n",
                            "0  4374910  small.en-tdrz   6.825107         53          99            184\n",
                            "0  4385939       small.en  10.298820        622          84            228\n",
                            "0  4385939  small.en-tdrz   7.543008         85         232            367"
                        ]
                    },
                    "execution_count": 10,
                    "metadata": {},
                    "output_type": "execute_result"
                }
            ],
            "source": [
                "cols = [\"call_id\", \"model\", \"value\", \"deletions\", \"insertions\", \"substitutions\"]\n",
                "results_all_df.query(\"metric=='wer_overall' and method=='punctuation'\")[cols].sort_values([\"call_id\", \"model\"])"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "There is also a difference in the time segments i.e. `segment_timestamped`. Lower recall here implies that the model is producing longer time segments.\n",
                "\n",
                "This is likely related to the nature of the finetuning data. Regularizing via more parameter-efficient finetuning methods might help avoid drastically changing the timestamp behavior."
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 11,
            "metadata": {},
            "outputs": [
                {
                    "data": {
                        "text/html": [
                            "<div>\n",
                            "<style scoped>\n",
                            "    .dataframe tbody tr th:only-of-type {\n",
                            "        vertical-align: middle;\n",
                            "    }\n",
                            "\n",
                            "    .dataframe tbody tr th {\n",
                            "        vertical-align: top;\n",
                            "    }\n",
                            "\n",
                            "    .dataframe thead th {\n",
                            "        text-align: right;\n",
                            "    }\n",
                            "</style>\n",
                            "<table border=\"1\" class=\"dataframe\">\n",
                            "  <thead>\n",
                            "    <tr style=\"text-align: right;\">\n",
                            "      <th></th>\n",
                            "      <th>call_id</th>\n",
                            "      <th>model</th>\n",
                            "      <th>value</th>\n",
                            "      <th>deletions</th>\n",
                            "      <th>insertions</th>\n",
                            "      <th>substitutions</th>\n",
                            "    </tr>\n",
                            "  </thead>\n",
                            "  <tbody>\n",
                            "    <tr>\n",
                            "      <th>3</th>\n",
                            "      <td>4359971</td>\n",
                            "      <td>small.en</td>\n",
                            "      <td>90.434784</td>\n",
                            "      <td>10</td>\n",
                            "      <td>0</td>\n",
                            "      <td>1</td>\n",
                            "    </tr>\n",
                            "    <tr>\n",
                            "      <th>3</th>\n",
                            "      <td>4359971</td>\n",
                            "      <td>small.en-tdrz</td>\n",
                            "      <td>74.782608</td>\n",
                            "      <td>22</td>\n",
                            "      <td>0</td>\n",
                            "      <td>7</td>\n",
                            "    </tr>\n",
                            "    <tr>\n",
                            "      <th>3</th>\n",
                            "      <td>4374910</td>\n",
                            "      <td>small.en</td>\n",
                            "      <td>60.000004</td>\n",
                            "      <td>19</td>\n",
                            "      <td>0</td>\n",
                            "      <td>3</td>\n",
                            "    </tr>\n",
                            "    <tr>\n",
                            "      <th>3</th>\n",
                            "      <td>4374910</td>\n",
                            "      <td>small.en-tdrz</td>\n",
                            "      <td>70.909088</td>\n",
                            "      <td>15</td>\n",
                            "      <td>0</td>\n",
                            "      <td>1</td>\n",
                            "    </tr>\n",
                            "    <tr>\n",
                            "      <th>3</th>\n",
                            "      <td>4385939</td>\n",
                            "      <td>small.en</td>\n",
                            "      <td>94.656494</td>\n",
                            "      <td>6</td>\n",
                            "      <td>0</td>\n",
                            "      <td>1</td>\n",
                            "    </tr>\n",
                            "    <tr>\n",
                            "      <th>3</th>\n",
                            "      <td>4385939</td>\n",
                            "      <td>small.en-tdrz</td>\n",
                            "      <td>80.152672</td>\n",
                            "      <td>21</td>\n",
                            "      <td>0</td>\n",
                            "      <td>5</td>\n",
                            "    </tr>\n",
                            "  </tbody>\n",
                            "</table>\n",
                            "</div>"
                        ],
                        "text/plain": [
                            "   call_id          model      value  deletions  insertions  substitutions\n",
                            "3  4359971       small.en  90.434784         10           0              1\n",
                            "3  4359971  small.en-tdrz  74.782608         22           0              7\n",
                            "3  4374910       small.en  60.000004         19           0              3\n",
                            "3  4374910  small.en-tdrz  70.909088         15           0              1\n",
                            "3  4385939       small.en  94.656494          6           0              1\n",
                            "3  4385939  small.en-tdrz  80.152672         21           0              5"
                        ]
                    },
                    "execution_count": 11,
                    "metadata": {},
                    "output_type": "execute_result"
                }
            ],
            "source": [
                "cols = [\"call_id\", \"model\", \"value\", \"deletions\", \"insertions\", \"substitutions\"]\n",
                "results_all_df.query(\"metric=='spk_turn_recall' and method=='segment_timestamped'\")[cols].sort_values([\"call_id\", \"model\"])"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "### Combining pyannote and transcription pipelines\n",
                "\n",
                "For our analysis we chose to transcribe segments output by pyannote after serializing them into a single order. This removes any ambiguity in speaker assignment, however can have a few edge cases due to duplicate overlapped segments created by Pyannote that are serialized out of order as seen with \"in your mind\" below. This particularly impacts WER around speaker switches (15% -> 23% as seen above).\n",
                "\n",
                "> For the serialization errors here, it is especially helpful to correlate precision errors with the original transcripts that contain timestamps. These can be found under `WORKDIR/transcripts/small.en/CALLID_drz_pre_sr/*.vtt`. \n",
                "\n",
                "![screenshot of transcript](duplicate-serialization.png)]\n",
                "\n",
                "Both ASR and diarization could also be run totally indepedently. This way the original WER is not affected. But it requires combining the two with careful heuristic matching of timestamps to handle various overlap/extra/duplicate segment edge cases. The best example of this is [WhisperX](https://github.com/m-bain/whisperX) which currently adds a 3rd model to get word-level timestamps to help matching. I went with a simple approach for ease of illustration, although it should be possible to compare the two approaches as well.\n",
                "\n",
                "*(as a sidenote, since reconciling duplicate/partially overlapped speech requires semantic information, I personally think it is cleanest and best done within the transcription pipeline itself as it has access to both acoustic and semantic information)*"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "### Extending with global clustering"
            ]
        },
        {
            "attachments": {},
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "Future work will explore extending segments produced by `tdrz_token` with global clustering. Here are some rough thoughts:\n",
                "- As we saw above, creating embeddings + clustering a given set of segments is much faster than the segmentation step itself, so it will remain relatively \"tiny\" and efficient ðŸ˜Š.\n",
                "- Since we're getting near-perfect precision from predicted speaker turns, they can actually be used as constraints during clustering as done in [Turn-to-Diarize](https://arxiv.org/abs/2109.11641).\n",
                "- An early implementation of AHC-based clustering is in `drz_post_sr` in `run_pipelines.py`, although we'll likely want to use [NMESC](https://github.com/tango4j/Auto-Tuning-Spectral-Clustering). Contributions are welcome!"
            ]
        }
    ],
    "metadata": {
        "kernelspec": {
            "display_name": "Python 3.9.16 ('tdrz')",
            "language": "python",
            "name": "python3"
        },
        "language_info": {
            "codemirror_mode": {
                "name": "ipython",
                "version": 3
            },
            "file_extension": ".py",
            "mimetype": "text/x-python",
            "name": "python",
            "nbconvert_exporter": "python",
            "pygments_lexer": "ipython3",
            "version": "3.9.16"
        },
        "orig_nbformat": 4,
        "vscode": {
            "interpreter": {
                "hash": "2bb77140dc548291d9467d2298e70a02631615c7599652cc807f295f0a493157"
            }
        }
    },
    "nbformat": 4,
    "nbformat_minor": 2
}
